{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import logging\n",
    "import contextlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "ROOT_DIR = os.path.abspath('.')\n",
    "sys.path.append(os.path.join(ROOT_DIR, 'data'))\n",
    "sys.path.append(os.path.join(ROOT_DIR, 'layers'))\n",
    "sys.path.append(os.path.join(ROOT_DIR, 'protos'))\n",
    "import yolact\n",
    "import yolactloss\n",
    "from data import coco_dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_height, image_width = 550, 550\n",
    "number_of_classes = 100\n",
    "aspect_ratios = [1, 0.5, 2]\n",
    "scales = [24, 48, 96, 192, 384]\n",
    "batch_size = 1\n",
    "training_iterations = 1200000\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 5 * 1e-4\n",
    "pretrained_checkpoints = ''\n",
    "print_interval = 0\n",
    "save_interval = 0\n",
    "validation_iterations = 5000\n",
    "\n",
    "training_data_path = ''\n",
    "validation_data_path = ''\n",
    "log_directory = ''\n",
    "checkpoint_directory = ''\n",
    "saved_model_directory = ''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "logging.info('Creating the Yolact model instance')\n",
    "model = yolact.Yolact(\n",
    "    image_height=image_height,\n",
    "    image_width=image_width,\n",
    "    fpn_channels=256,\n",
    "    number_of_classes=number_of_classes + 1,\n",
    "    number_of_masks=32,\n",
    "    aspect_ratios=aspect_ratios,\n",
    "    scales=scales,\n",
    "    base_model_trainable=False\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "logging.info(f'Creating the training dataloader from {training_data_path}...')\n",
    "training_dataset = coco_dataset.prepare_dataset(\n",
    "    image_height=image_height,\n",
    "    image_width=image_width,\n",
    "    feature_map_sizes=model.feature_map_size,\n",
    "    protonet_out_sizes=model.protonet_out_size,\n",
    "    aspect_ratios=aspect_ratios,\n",
    "    scales=scales,\n",
    "    tfrecord_directory=training_data_path,\n",
    "    batch_size=batch_size)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "logging.info(f'Creating the validation dataloader from: {validation_data_path}...')\n",
    "validation_dataset = coco_dataset.prepare_dataset(\n",
    "    image_height=image_height,\n",
    "    image_width=image_width,\n",
    "    feature_map_sizes=model.feature_map_size,\n",
    "    protonet_out_sizes=model.protonet_out_size,\n",
    "    aspect_ratios=[float(i) for i in aspect_ratios],\n",
    "    scales=[int(i) for i in scales],\n",
    "    tfrecord_directory=validation_data_path,\n",
    "    batch_size=1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "learning_rate_schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [int(0.8 * training_iterations), int(0.9 * training_iterations), int(0.95 * training_iterations)],\n",
    "    [learning_rate, 0.1 * learning_rate, 0.01 * learning_rate, 0.001 * learning_rate])\n",
    "\n",
    "logging.info('Initiate the optimizer and loss function...')\n",
    "\n",
    "optimizer = tfa.optimizers.SGDW(\n",
    "    learning_rate=learning_rate_schedule,\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay)\n",
    "\n",
    "criterion = yolactloss.YOLACTLoss(\n",
    "    img_h=image_height,\n",
    "    img_w=image_width)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "training_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "validation_loss = tf.keras.metrics.Mean('valid_loss', dtype=tf.float32)\n",
    "location = tf.keras.metrics.Mean('loc_loss', dtype=tf.float32)\n",
    "config = tf.keras.metrics.Mean('conf_loss', dtype=tf.float32)\n",
    "mask = tf.keras.metrics.Mean('mask_loss', dtype=tf.float32)\n",
    "mask_iou = tf.keras.metrics.Mean('mask_iou_loss', dtype=tf.float32)\n",
    "segmentation = tf.keras.metrics.Mean('seg_loss', dtype=tf.float32)\n",
    "v_loc = tf.keras.metrics.Mean('vloc_loss', dtype=tf.float32)\n",
    "v_conf = tf.keras.metrics.Mean('vconf_loss', dtype=tf.float32)\n",
    "v_mask = tf.keras.metrics.Mean('vmask_loss', dtype=tf.float32)\n",
    "v_mask_iou = tf.keras.metrics.Mean('vmask_iou_loss', dtype=tf.float32)\n",
    "v_seg = tf.keras.metrics.Mean('vseg_loss', dtype=tf.float32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "logging.info('Setup tensorboard...')\n",
    "train_log_dir = os.path.join(log_directory, 'train')\n",
    "test_log_dir = os.path.join(log_directory, 'test')\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "logging.info('Start the training process')\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "    step=tf.Variable(1), optimizer=optimizer, model=model)\n",
    "manager = tf.train.CheckpointManager(\n",
    "    checkpoint, directory=checkpoint_directory, max_to_keep=5)\n",
    "\n",
    "if manager.latest_checkpoint:\n",
    "    logging.info(f'Restored from {manager.latest_checkpoint}')\n",
    "else:\n",
    "    if pretrained_checkpoints != '':\n",
    "        feature_extractor_model = tf.train.Checkpoint(\n",
    "            backbone_resnet=model.backbone_resnet,\n",
    "            backbone_fpn=model.backbone_fpn,\n",
    "            protonet=model.protonet)\n",
    "        ckpt = tf.train.Checkpoint(pretrained_checkpoints).expect_partial()\\\n",
    "            .assert_existing_objects_matched()\n",
    "        logging.info(f'Backbone restored from {pretrained_checkpoints}')\n",
    "    else:\n",
    "        logging.info('Initializing without checkpoints.')\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@contextlib.contextmanager\n",
    "def options(options):\n",
    "    old_opts = tf.config.optimizer.get_experimental_options()\n",
    "    tf.config.optimizer.set_experimental_options(options)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        tf.config.optimizer.set_experimental_options(old_opts)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_val = 1e10\n",
    "iterations = checkpoint.step.numpy()\n",
    "\n",
    "for image, labels in training_dataset:\n",
    "    if iterations > training_iterations:\n",
    "        break\n",
    "\n",
    "    checkpoint.step.assign_add(1)\n",
    "    iterations += 1\n",
    "\n",
    "    with options({'constant_folding': True,\n",
    "                  'layout_optimize': True,\n",
    "                  'loop_optimization': True,\n",
    "                  'arithmetic_optimization': True,\n",
    "                  'remapping': True}):\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = model(image, training=True)\n",
    "\n",
    "            loc_loss, conf_loss, mask_loss, mask_iou_loss, seg_loss, total_loss = \\\n",
    "                criterion(model, output, labels, number_of_classes + 1)\n",
    "        grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        training_loss.update_state(total_loss)\n",
    "\n",
    "    location.update_state(loc_loss)\n",
    "    config.update_state(conf_loss)\n",
    "    mask.update_state(mask_loss)\n",
    "    mask_iou.update_state(mask_iou_loss)\n",
    "    segmentation.update_state(seg_loss)\n",
    "\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('Total loss',\n",
    "                          training_loss.result(), step=iterations)\n",
    "\n",
    "        tf.summary.scalar('Loc loss',\n",
    "                          location.result(), step=iterations)\n",
    "\n",
    "        tf.summary.scalar('Conf loss',\n",
    "                          config.result(), step=iterations)\n",
    "\n",
    "        tf.summary.scalar('Mask loss',\n",
    "                          mask.result(), step=iterations)\n",
    "\n",
    "        tf.summary.scalar('Mask IOU loss',\n",
    "                          mask_iou.result(), step=iterations)\n",
    "\n",
    "        tf.summary.scalar('Seg loss',\n",
    "                          segmentation.result(), step=iterations)\n",
    "\n",
    "    if iterations and iterations % print_interval == 0:\n",
    "        logging.info(f'Iteration {iterations}, LR: {optimizer._decayed_lr(var_dtype=tf.float32)}, ' +\n",
    "                     f'Total loss: {training_loss.result()}, B: {location.result()}, ' +\n",
    "                     f'C: {config.result()}, M: {mask.result()}, I: {mask_iou.result()}, ' +\n",
    "                     f'S: {segmentation.result()}')\n",
    "\n",
    "    if iterations and iterations % save_interval == 0:\n",
    "        save_path = manager.save()\n",
    "\n",
    "        logging.info(\n",
    "            f'Saved checkpoint for step {int(checkpoint.step)} to {save_path}')\n",
    "\n",
    "        validation_iterator = 0\n",
    "        for validation_image, validation_labels in validation_dataset:\n",
    "            if validation_iterator > validation_iterations:\n",
    "                break\n",
    "\n",
    "            with options({'constant_folding': True,\n",
    "                          'layout_optimize': True,\n",
    "                          'loop_optimization': True,\n",
    "                          'arithmetic_optimization': True,\n",
    "                          'remapping': True}):\n",
    "                output = model(validation_image, training=False)\n",
    "\n",
    "                validation_location_loss, validation_config_loss, validation_mask_loss, \\\n",
    "                    validation_mask_iou_loss, validation_segmentation_loss, validation_total_loss = \\\n",
    "                    criterion(model, output, validation_labels,\n",
    "                              number_of_classes + 1)\n",
    "\n",
    "                validation_loss.update(validation_total_loss)\n",
    "\n",
    "                _h = validation_image.shape[1]\n",
    "                _w = validation_image.shape[2]\n",
    "\n",
    "                number_of_ground_truths = validation_labels['num_obj'][0].numpy(\n",
    "                )\n",
    "                ground_truth_boxes = validation_labels['boxes_norm'][0][:number_of_ground_truths]\n",
    "                ground_truth_boxes = ground_truth_boxes.numpy() * \\\n",
    "                    np.array([_h, _w, _h, _w])\n",
    "                ground_truth_classes = validation_labels['classes'][0][:number_of_ground_truths].numpy(\n",
    "                )\n",
    "                ground_truth_masks = validation_labels['mask_target'][0][:number_of_ground_truths].numpy(\n",
    "                )\n",
    "\n",
    "                ground_truth_masked_image = np.zeros(\n",
    "                    (number_of_ground_truths, _h, _w))\n",
    "                for _b in range(number_of_ground_truths):\n",
    "                    _mask = ground_truth_masks[_b].astype(\"uint8\")\n",
    "                    _mask = cv2.resize(_mask, (_w, _h))\n",
    "                    ground_truth_masked_image[_b] = _mask\n",
    "\n",
    "                number_of_detections = np.count_nonzero(\n",
    "                    output['detection_scores'][0].numpy() > 0.05)\n",
    "\n",
    "                detection_boxes = output['detection_boxes'][0][:number_of_detections]\n",
    "                detection_boxes = detection_boxes.numpy() * \\\n",
    "                    np.array([_h, _w, _h, _w])\n",
    "                detection_masks = output['detection_masks'][0][:number_of_detections].numpy(\n",
    "                )\n",
    "                detection_masks = (detection_masks > 0.5)\n",
    "\n",
    "                detection_scores = output['detection_scores'][0][:number_of_detections].numpy(\n",
    "                )\n",
    "                detection_classes = output['detection_classes'][0][:number_of_detections].numpy(\n",
    "                )\n",
    "\n",
    "                masked_detection_image = np.zeros(\n",
    "                    (number_of_detections, _h, _w))\n",
    "                for _b in range(number_of_detections):\n",
    "                    _mask = detection_masks[_b].astype(\"uint8\")\n",
    "                    _mask = cv2.resize(_mask, (_w, _h))\n",
    "                    masked_detection_image[_b] = _mask\n",
    "\n",
    "            v_loc.update_state(validation_location_loss)\n",
    "            v_conf.update_state(validation_config_loss)\n",
    "            v_mask.update_state(validation_mask_loss)\n",
    "            v_mask_iou.update_state(validation_mask_iou_loss)\n",
    "            v_seg.update_state(validation_segmentation_loss)\n",
    "            validation_iterator += 1\n",
    "\n",
    "        with test_summary_writer.as_default():\n",
    "            tf.summary.scalar('V Total loss',\n",
    "                              validation_loss.result(), step=iterations)\n",
    "\n",
    "            tf.summary.scalar('V Loc loss',\n",
    "                              v_loc.result(), step=iterations)\n",
    "\n",
    "            tf.summary.scalar('V Conf loss',\n",
    "                              v_conf.result(), step=iterations)\n",
    "\n",
    "            tf.summary.scalar('V Mask loss',\n",
    "                              v_mask.result(), step=iterations)\n",
    "\n",
    "            tf.summary.scalar('V Mask IOU loss',\n",
    "                              v_mask_iou.result(), step=iterations)\n",
    "\n",
    "            tf.summary.scalar('V Seg loss',\n",
    "                              v_seg.result(), step=iterations)\n",
    "\n",
    "        train_template = (\"Iteration {}, Train Loss: {}, Loc Loss: {},  \"\n",
    "                          \"Conf Loss: {}, Mask Loss: {}, Mask IOU Loss: {}, Seg Loss: {}\")\n",
    "\n",
    "        valid_template = (\"Iteration {}, Valid Loss: {}, V Loc Loss: {},  \"\n",
    "                          \"V Conf Loss: {}, V Mask Loss: {}, V Mask IOU Loss: {}, \"\n",
    "                          \"Seg Loss: {}\")\n",
    "\n",
    "        logging.info(train_template.format(iterations + 1,\n",
    "                                           training_loss.result(),\n",
    "                                           location.result(),\n",
    "                                           config.result(),\n",
    "                                           mask.result(),\n",
    "                                           mask_iou.result(),\n",
    "                                           segmentation.result()))\n",
    "        logging.info(valid_template.format(iterations + 1,\n",
    "                                           validation_loss.result(),\n",
    "                                           v_loc.result(),\n",
    "                                           v_conf.result(),\n",
    "                                           v_mask.result(),\n",
    "                                           v_mask_iou.result(),\n",
    "                                           v_seg.result()))\n",
    "\n",
    "        if validation_loss.result() < best_val:\n",
    "            best_val = validation_loss.result()\n",
    "\n",
    "            save_options = tf.saved_model.SaveOptions(\n",
    "                namespace_whitelist=['Addons'])\n",
    "            model.save(os.path.join(saved_model_directory, 'saved_model_'\n",
    "                                    + str(validation_loss.result().numpy())), options=save_options)\n",
    "    \n",
    "    training_loss.reset_states()\n",
    "    location.reset_states()\n",
    "    config.reset_states()\n",
    "    mask.reset_states()\n",
    "    mask_iou.reset_states()\n",
    "    segmentation.reset_states()\n",
    "\n",
    "    validation_loss.reset_states()\n",
    "    v_loc.reset_states()\n",
    "    v_conf.reset_states()\n",
    "    v_mask.reset_states()\n",
    "    v_mask_iou.reset_states()\n",
    "    v_seg.reset_states()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = tf.saved_model.load('./saved_models/saved_model_0.17916931')\n",
    "infer = model.signatures[\"serving_default\"]\n",
    "\n",
    "img = cv2.imread('test.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (550, 550)).astype(np.float32)\n",
    "output = infer(tf.constant(img[None, ...]))\n",
    "\n",
    "_h = img.shape[0]\n",
    "_w = img.shape[1]\n",
    "\n",
    "det_num = output['num_detections'][0].numpy()\n",
    "det_boxes = output['detection_boxes'][0][:det_num]\n",
    "det_boxes = det_boxes.numpy()*np.array([_h,_w,_h,_w])\n",
    "det_masks = output['detection_masks'][0][:det_num].numpy()\n",
    "\n",
    "det_scores = output['detection_scores'][0][:det_num].numpy()\n",
    "det_classes = output['detection_classes'][0][:det_num].numpy()\n",
    "\n",
    "for i in range(det_num):\n",
    "    score = det_scores[i]\n",
    "    if score > 0.5:\n",
    "        box = det_boxes[i].astype(int)\n",
    "        _class = det_classes[i]\n",
    "        cv2.rectangle(img, (box[1], box[0]), (box[3], box[2]), (0, 255, 0), 2)\n",
    "        cv2.putText(img, str(_class)+'; '+str(round(score,2)), (box[1], box[0]), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), lineType=cv2.LINE_AA)\n",
    "        mask = det_masks[i]\n",
    "        mask = cv2.resize(mask, (_w, _h))\n",
    "        mask = (mask > 0.5)\n",
    "        roi = img[mask]\n",
    "        blended = roi.astype(\"uint8\")\n",
    "        img[mask] = blended*[0,0,1]\n",
    "\n",
    "cv2.imwrite(\"out.jpg\", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "7e1012a4e3e5696f926c9c506dd1f8abdf2d37af44babf01307d329dcbd67456"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}